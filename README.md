# Automated Prompt Engineering (APE) - Cybersecurity for LLMs

## Overview

During this hackathon, we explore a new paradigm in prompt engineering called Automated Prompt Engineering (APE). APE leverages Large Language Models (LLMs) to autonomously generate, evaluate, and refine prompts for LLM cybersecurity tasks (i.e. prompt hacking).

## How it works

Very simply, APE leverages **5 agents**:
1. **Attacker**: This agent generates an attack prompt designed to exploit vulnerabilities in the target LLM, i.e. make the LLM reveal sensitive information or perform unauthorized actions.
2. **Defender**: This agent creates a defense prompt aimed at mitigating the attacker's prompt, enhancing the security of the target LLM.
3. **Tester**: This agent is given both prompts (attack and defense) alongside sensitive information. It evaluates the effectiveness of the attack and defense prompts by determining whether the sensitive information is successfully protected or compromised.
4. **Orchestrator**: This agent oversees the entire process, coordinating the interactions between the attacker, defender, and tester agents. It ensures that the prompts are generated, evaluated, and refined in a systematic manner.
5. **Summarizer**: This agent compiles the results of the testing phase, providing insights into the effectiveness of the attack and defense strategies. It is in charge of generating a final report summarizing the findings.


Using these agents, APE iterates $n$ rounds of prompt generation, testing, and refinement to enhance the security of LLMs against prompt-based attacks. 

## Reports generated

You may find below sample reports generated by the Summarizer agent:
- [Report 1: Prompt injection with fixed recipe](papers/1/report.pdf) ($n=3$ rounds)
- [Report 2: Prompt injection with fixed recipe #2](papers/2/report.pdf) ($n=3$ rounds)
- [Report 3: Prompt injection with free recipe](papers/3/report.pdf) ($n=3$ rounds)
