# Automated Prompt Engineering (APE) - Cybersecurity for LLMs

## Overview

During this hackathon, we explore a new paradigm in prompt engineering called Automated Prompt Engineering (APE). APE leverages Large Language Models (LLMs) to autonomously generate, evaluate, and refine prompts for LLM cybersecurity tasks (i.e. prompt hacking).

## Motivation

As LLMs become increasingly integrated into various applications, ensuring their security against prompt-based attacks is paramount. Traditional prompt engineering methods often rely on manual efforts, which can be time-consuming and may not cover all potential vulnerabilities. APE aims to automate this process, enabling continuous improvement in LLM security through iterative prompt generation and evaluation.

## How it works

Very simply, APE leverages **5 agents**:
1. **Attacker**: This agent generates an attack prompt designed to exploit vulnerabilities in the target LLM, i.e. make the LLM reveal sensitive information or perform unauthorized actions.
2. **Defender**: This agent creates a defense prompt aimed at mitigating the attacker's prompt, enhancing the security of the target LLM.
3. **Tester**: This agent is given both prompts (attack and defense) alongside sensitive information. It evaluates the effectiveness of the attack and defense prompts by determining whether the sensitive information is successfully protected or compromised.
4. **Orchestrator**: This agent oversees the entire process, coordinating the interactions between the attacker, defender, and tester agents. It ensures that the prompts are generated, evaluated, and refined in a systematic manner.
5. **Summarizer**: This agent compiles the results of the testing phase, providing insights into the effectiveness of the attack and defense strategies. It is in charge of generating a final report summarizing the findings.


The attacker and defender use Web search in order to find cutting-edge prompt engineering techniques to improve their prompts at each round. The results are extremely impressive. 

Using these agents, APE iterates $n$ rounds of prompt generation, testing, and refinement to enhance the security of LLMs against prompt-based attacks. 

<img width="430" height="536" alt="ScheÌma " src="https://github.com/user-attachments/assets/c35813a1-2d63-45b5-99cf-e090915b2a30" />



## Reports generated

The defender often wins but sometimes the attacker manages to bypass the defense! The results are very impressive overall. I'll hope you enjoy them as much as we did.

You may find below sample reports generated by the Summarizer agent:
- [Report 1: Prompt injection with fixed recipe](papers/1/report.pdf) ($n=3$ rounds)
- [Report 2: Prompt injection with fixed recipe #2](papers/2/report.pdf) ($n=3$ rounds)
- [Report 3: Prompt injection with free recipe](papers/3/report.pdf) ($n=3$ rounds)
- [Report 4: Prompt injection with free recipe #2](papers/4/report.pdf) ($n=8$ rounds)
- [Report 5: Multiturn conversation](papers/5/report.pdf) ($n=3$ rounds)
- [Report 6: Multiturn conversation (full transcript) #2](papers/7/report.pdf) ($n=3$ rounds) Highly detailed full transcript version; very interesting
- [Report 7: Multiturn conversation #3](papers/6/report.pdf) ($n=3$ rounds)
- [Report 8: Strong attacker prompt - multiturn](papers/8/report.pdf) ($n=3$ rounds) Highly interesting because of high effectiveness variance for attacker/defender
- [Report 9: Medium attacker prompt - multiturn](papers/9/report.pdf) ($n=3$ rounds)
- [Report 10: Strong attacker prompt - multiturn (20 turns)](papers/10/report.pdf) ($n=3$ rounds)
- [Report 11: Medium attacker prompt - multiturn](papers/11/report.pdf) ($n=5$ rounds)
